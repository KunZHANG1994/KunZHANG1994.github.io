<!DOCTYPE html>
<html>

<head style="font-family: sans-serif">
  <title>ZHANG KUN</title>
  <link rel="stylesheet" type="text/css" href="zk.css">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-B1GX1SDN9Q"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-B1GX1SDN9Q');
  </script>
  <script async defer src="https://buttons.github.io/buttons.js"></script>
</head>


<body style="max-width: 850px;margin-left: auto;margin-right: auto; margin-bottom: 10px; font-family: sans-serif">
  <table>
    <tbody>
      <tr>
        <td style="padding:0 0 0 0"><img src="images/me.jpg" style="width:150px" /></td>
        <td style="vertical-align:top; padding: 0 0 0 50px">
          <h1 style="font-size: 35px">
          Aaron, Kun ZHANG
          </h1>
          <p><b>Resume:</b><a href="files/cv_zk.pdf">[cv]</a> </p>
          <p><b>Email:</b> kun.zhang [at] connect[dot]ust [dot] hk</p>
          <p><b>Research Interests:</b><p></p>
          <p> Robotics Perception, Manipulation, & Electromechanical System Design</p>
          
        </td>
        </td>
    </tbody>
  </table>

  <table style="margin: 0px 0px">
    <tr>
      <td style="padding:0 0px 0px 0;">
        <a href="https://scholar.google.com/citations?hl=zh-TW&user=cQ8W5Z4AAAAJ">
          <img src="images/scholar.jpg" width=30px, height=30px />
        </a>
      </td>
      <td style="padding:0 0px 0px 10px;">
        <a href="https://www.linkedin.com/in/kun-zhang-b65652165/">
          <img src="images/linkedin.png" width=30px, height=30px />
        </a>
      </td>
      <td style="padding:0 0px 0px 10px;">
        <a href="https://github.com/KunZHANG1994">
          <img src="images/github.png" width=30px, height=30px />
        </a>
      </td>
      <!-- <td style="padding:0 0px 0px 10px;">
        <a href="https://www.youtube.com">
          <img src="images/youtube.png" width=30px, height=30px />
        </a>
      </td> -->
    </tr>
  </table>
  <p style="color:gray">“利而不害，为而不争”</p>
  <p>Currently, I am a PhD candidate from the Robotics Institute of HKUST. And working on the deformable object manipulation problem, especially textile and garment.</p>

  <h2>Update:</h2>
  <ul>
    <li><span class='gray'>[22-Sep-2023]</span> One paper was accepted by RAL2023;
    <li><span class='gray'>[22-June-2023]</span> One paper was accepted by IROS2023;
    <li><span class='gray'>[25-May-2023]</span> One paper was accepted by CASE2023;
    <li><span class='gray'>[17-Jan-2023]</span> One paper was accepted by ICRA2023;
    <li><span class='gray'>[30-Oct-2020]</span> I passed the PQE exam;  
    <li><span class='gray'>[18-Aug-2019]</span> I become a PhD student of HKUST;
  </ul>

  <h2> Experience:</h2>
  <ul>
    <li><span class='gray'>[2021.05-2021.08]</span> Tencent Robotics-X Lab Control Center Intern;
    <li><span class='gray'>[2019.08-2019.12]</span> Shenzhen Dorabot Company Robotics Software Intern;  
  </ul>

  <h2>Projects:</h2>

  <table style="width: 1000;margin: 0px 10px">
    <tbody>
      <tr>
        <td style="width: 200px;padding:0 15px 40px 0;"><img src="images/DORF.png" width=300px,
            height=200px />
        </td>
        <td style="vertical-align:top;font-size: 15px"><b>Mobile: Dynamic Objects Removal</b>
        <br>
        <span class='gray'>[2023.01-2023.05]</span>
        <br>
        <br>
        -<i>IEEE  IEEE Robotics and Automation Letters (RAL),2023</i> <a href="https://ieeexplore.ieee.org">[paper(not yet available)]</a>
        <br>
        <br>
        We propose DORF (Dynamic Object Removal Framework), a novel coarse-to-fine offline framework that exploits 
        global 4D spatial-temporal LiDAR information to achieve clean static point cloud map generation
        <br>
        </td>
      </tr>
      <tr> 
    </tbody>
  </table>

  <table style="width: 1000;margin: 0px 10px">
    <tbody>
      <tr>
        <td style="width: 200px;padding:0 15px 40px 0;"><img src="images/gripper.GIF" width=200px,
            height=250px />
        </td>
        <td style="vertical-align:top;font-size: 15px"><b>Design and Test of A Novel Modular Dexterous Gripper</b>
          <br>
          <span class='gray'>[2022.10-2023.03]</span>
          <br>
          <br>
          -<i>IEEE International Conference on Automation Science and Engineering(CASE),2023</i> 
          <a href="https://patents.google.com/patent/CN116690630A/zh?oq=CN116690630A">[Patent]</a>
          <a href="https://ieeexplore.ieee.org">[paper(not yet available)]</a>
          <br>
          <br>
          We develop a modular dexterous end-effector prototype for grasping pieces of garments from a flat platform. 
          <br>
          
        </td>
      </tr>
      <tr> 
    </tbody>
  </table>

  <table style="width: 1000;margin: 0px 10px">
    <tbody>
      <tr>
        <td style="width: 200px;padding:0 15px 40px 0;"><img src="images/PeginHole.jpg" width=200px,
            height=200px />
        </td>
        <td style="vertical-align:top;font-size: 15px"><b>Peg-in-hole Manipulation</b>
          <br>
          <span class='gray'>[2021.10-2022.09]</span>
          <br>
          <br>
          -<i>IEEE International Conference on Robotics and Automation(ICRA),2023<i> <a href="https://ieeexplore.ieee.org/abstract/document/10161116">[paper]</a>
          <br>
          <br>
          We develop a six-dimensional (6D) perceptive robotic assembly system that utilizes an in-hand RGB-D camera 
          for peg-in-hole with multiple types of practical connectors.
          <br>
          <br>
          -<i>IEEE/RSJ International Conference on Intelligent Robots and Systems(IROS),2023<i> <a href="https://ieeexplore.ieee.org">[paper(not yet available)]</a>
          <br>
          <br>
          We propose a novel search strategy for robotic insertion tasks that actively utilizes the information contained in the contact configuration. 
          Our method is based purely on the robots proprioceptive sensing and does not need visual or tactile sensors.
          <br>
          
          
        </td>
      </tr>
      <tr> 
    </tbody>
  </table>

  <table style="width: 1000;margin: 0px 10px">
    <tbody>
      <tr>
        <td style="width: 200px;padding:0 15px 40px 0;"><img src="images/toss.GIF" width=200px,
            height=150px />
        </td>
        <td style="vertical-align:top;font-size: 15px"><b>Joggling manipulation: Tossing</b>
          <br>
          <span class='gray'>[2021.05 - 2021.08]</span>
          <br>
          <br>
          <i>Prior work for : <a href=" https://mp.weixin.qq.com/s/Xsbn6cvCiN7gNJVZdrbQMA">Tencent Robotics-X Bartending Demo: Tossing Part</a> <i>
          <br>
          <br>
          We investigate whether using solely the on-board proprioceptive sensory modalities (e.g. F/T) can effectively capture
          and characterize typical dynamic manipulation processes. 
          <br>
          
          
        </td>
      </tr>
      <tr> 
    </tbody>
  </table>

  <table style="width: 1000;margin: 0px 10px">
    <tbody>
      <tr>
        <td style="width: 200px;padding:0 15px 40px 0;"><img src="images/MobileManipulation.jpg" width=200px,
            height=150px />
        </td>
        <td style="vertical-align:top;font-size: 15px"><b>Design and Test of A Novel Mobile Manipulator </b>
          <br>
          <span class='gray'>[2021.01 - 2021.05]</span>
          <br>
          <br>
          We developed a mobile manipulator platform for study. 
          The platform consists of a mobile chassis and a lightweight robotic arm, 
          and is equipped with a microprocessor, as well as a variety of sensors such as radar and depth cameras.
          <br>
        </td>
      </tr>
      <tr> 
    </tbody>
  </table>

  <table style="width: 1000;margin: 0px 10px">
    <tbody>
      <tr>
        <td style="width: 200px;padding:0 15px 40px 0;"><img src="images/balance.GIF" width=200px,
            height=150px />
        </td>
        <td style="vertical-align:top;font-size: 15px"><b>Nonprehensile Manipulation: Ball Balancing</b>
          <br>
          <span class='gray'>[2020.07-2020.10]</span>
          <br>
          <br>
          We developed a ball balancing system using a cooperative robot arm and a motion capture system, 
          which can accurately obtain the position of the ball, and using the force feedback 
          at the end of the robot arm to maintain the balance of the ball on a plate in the case of interference.
          <br>
        </td>
      </tr>
      <tr> 
    </tbody>
  </table>

  <table style="width: 1000;margin: 0px 10px">
    <tbody>
      <tr>
        <td style="width: 200px;padding:0 15px 40px 0;"><img src="images/MambaArm.GIF" width=200px,
            height=200px />
        </td>
        <td style="vertical-align:top;font-size: 15px"><b>Design and Test of A Novel Modular Force Control Manipulator</b>
          <br>
          <span class='gray'>[2020.02 - 2020.07]</span>
          <br>
          <br>
          We developed a modular force control manipulator prototype. This arm supports torque command control, 
          the lightweight body is designed with carbon fiber linkages, and the structure can be 
          switched between 4 and 6 degrees of freedom modes according to the actual needs of the work.
          <br>
        </td>
      </tr>
      <tr> 
    </tbody>
  </table>



  
  <table style="width: 1000;margin: 0px 10px">
    <tbody>
      <tr>
        <td style="width: 200px;padding:0 15px 40px 0;"><img src="images/ToolsDataset.jpg" width=400px,
            height=200px />
        </td>
        <td style="vertical-align:top;font-size: 15px"><b>Machine Tools Recognition System</b>
          <br>
          <span class='gray'>[2016.10 - 2018.10]</span>
          <br>
          -International Conference on Extreme Learning Machine(ELM),2018 <a href="https://link.springer.com/chapter/10.1007/978-3-030-23307-5_27">[paper]</a> 
          <br>
          -Cognitive Computation,2018 <a href="https://link.springer.com/article/10.1007/s12559-018-9598-1">[paper]</a>
          <br>
          -IEEE Access,2020 <a href="https://ieeexplore.ieee.org/abstract/document/8954685">[paper]</a>
          <br>
          <br>
          We proposed a machine tools recognition system. The hybrid networks of Convolutional Neural Networks (CNNs) 
          and Extreme Learning Machine (ELM) are developed for a 3D machine tools database recognition, which we constructed.
          <br>
          
        </td>
      </tr>
      <tr> 
    </tbody>
  </table>


  <!-- <HR align=left width=800 color='gray' SIZE=1> -->
    
  <table style="width: 1000;margin: 0px 10px">
    <tbody>
      <tr>
        <td style="width: 200px;padding:0 15px 40px 0;"><img src="images/ClosingDevice.GIF" width=200px,
            height=200px />
        </td>
        <td style="vertical-align:top;font-size: 15px"><b>Intelligent Energy-saving Automatic Closing Device for Refrigerators</b>
          <br>
          <span class='gray'>[2014.10 - 2015.05]</span>
          <br>
          <i>National innovation and entrepreneurship training program for college students</i>
          <br>
          <a href="https://patents.google.com/patent/CN105332583B/zh?oq=CN105332583B">[Patent]</a>
          <a href="http://www.cqvip.com/qk/87241x/201512/666800346.html">[Paper]</a>
          <br>
          <br>
          We designed a prototype of a door close machine, which realized automatic reset function with constant speed by using ratchet, friction blocks and gear set.
          <br>

        </td>
      </tr>
      <tr> 
    </tbody>
  </table>

</body>

<br>
<br>
<br>
<br>

<p style="text-align: center;font-size: 12px">
  <img src="images/wechat.jpg" style="height:100px;"><br>
  &copy ZK. All rights reserved
</p>


</html>
